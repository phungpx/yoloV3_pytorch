{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e1310c-b6a6-4ab5-b284-9f66ab54221f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa369ca7-10f0-4187-8d5b-b1682036fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\"\"\" \n",
    "Information about architecture config:\n",
    "Tuple is structured by (filters, kernel_size, stride) \n",
    "Every conv is a same convolution. \n",
    "List is structured by \"B\" indicating a residual block followed by the number of repeats\n",
    "\"S\" is for scale prediction block and computing the yolo loss\n",
    "\"U\" is for upsampling the feature map and concatenating with a previous layer\n",
    "\"\"\"\n",
    "config = [\n",
    "    (32, 3, 1),\n",
    "    (64, 3, 2),\n",
    "    [\"B\", 1],\n",
    "    (128, 3, 2),\n",
    "    [\"B\", 2],\n",
    "    (256, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (512, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (1024, 3, 2),\n",
    "    [\"B\", 4],  # To this point is Darknet-53\n",
    "    (512, 1, 1),\n",
    "    (1024, 3, 1),\n",
    "    \"S\",\n",
    "    (256, 1, 1),\n",
    "    \"U\",\n",
    "    (256, 1, 1),\n",
    "    (512, 3, 1),\n",
    "    \"S\",\n",
    "    (128, 1, 1),\n",
    "    \"U\",\n",
    "    (128, 1, 1),\n",
    "    (256, 3, 1),\n",
    "    \"S\",\n",
    "]\n",
    "\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bn_act=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            bias=not bn_act,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.leaky = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.use_bn_act = bn_act\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_bn_act:\n",
    "            return self.leaky(self.bn(self.conv(x)))\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, use_residual=True, num_repeats=1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for repeat in range(num_repeats):\n",
    "            self.layers += [\n",
    "                nn.Sequential(\n",
    "                    CNNBlock(channels, channels // 2, kernel_size=1),\n",
    "                    CNNBlock(channels // 2, channels, kernel_size=3, padding=1),\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        self.use_residual = use_residual\n",
    "        self.num_repeats = num_repeats\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            if self.use_residual:\n",
    "                x = x + layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ScalePrediction(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pred = nn.Sequential(\n",
    "            CNNBlock(in_channels, 2 * in_channels, kernel_size=3, padding=1),\n",
    "            CNNBlock(\n",
    "                2 * in_channels, (num_classes + 5) * 3, bn_act=False, kernel_size=1\n",
    "            ),\n",
    "        )\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (\n",
    "            self.pred(x)\n",
    "            .reshape(x.shape[0], 3, self.num_classes + 5, x.shape[2], x.shape[3])\n",
    "            .permute(0, 1, 3, 4, 2)\n",
    "        )\n",
    "\n",
    "\n",
    "class YOLOv3(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=80):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.layers = self._create_conv_layers()\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []  # for each scale\n",
    "        route_connections = []\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ScalePrediction):\n",
    "                outputs.append(layer(x))\n",
    "                continue\n",
    "\n",
    "            x = layer(x)\n",
    "\n",
    "            if isinstance(layer, ResidualBlock) and layer.num_repeats == 8:\n",
    "                route_connections.append(x)\n",
    "\n",
    "            elif isinstance(layer, nn.Upsample):\n",
    "                x = torch.cat([x, route_connections[-1]], dim=1)\n",
    "                route_connections.pop()\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def _create_conv_layers(self):\n",
    "        layers = nn.ModuleList()\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for module in config:\n",
    "            if isinstance(module, tuple):\n",
    "                out_channels, kernel_size, stride = module\n",
    "                layers.append(\n",
    "                    CNNBlock(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding=1 if kernel_size == 3 else 0,\n",
    "                    )\n",
    "                )\n",
    "                in_channels = out_channels\n",
    "\n",
    "            elif isinstance(module, list):\n",
    "                num_repeats = module[1]\n",
    "                layers.append(ResidualBlock(in_channels, num_repeats=num_repeats,))\n",
    "\n",
    "            elif isinstance(module, str):\n",
    "                if module == \"S\":\n",
    "                    layers += [\n",
    "                        ResidualBlock(in_channels, use_residual=False, num_repeats=1),\n",
    "                        CNNBlock(in_channels, in_channels // 2, kernel_size=1),\n",
    "                        ScalePrediction(in_channels // 2, num_classes=self.num_classes),\n",
    "                    ]\n",
    "                    in_channels = in_channels // 2\n",
    "\n",
    "                elif module == \"U\":\n",
    "                    layers.append(nn.Upsample(scale_factor=2),)\n",
    "                    in_channels = in_channels * 3\n",
    "\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8504b415-c58b-44c7-ad0f-ab3350060462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "model = YOLOv3(num_classes=20)\n",
    "\n",
    "dummy_tensor = torch.randn((2, 3, 416, 416))\n",
    "\n",
    "outputs = model(dummy_tensor)\n",
    "\n",
    "assert outputs[0].shape == (2, 3, 416 // 32, 416 // 32, 20 + 5)\n",
    "assert outputs[1].shape == (2, 3, 416 // 16, 416 // 16, 20 + 5)\n",
    "assert outputs[2].shape == (2, 3, 416 // 8, 416 // 8, 20 + 5)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac7ab6-0ed2-4ace-ab94-39568ccb0c08",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c71fda6-1fd6-40fc-90e6-da0a4679c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def _resize(image: np.ndarray, imsize=416) -> np.ndarray:\n",
    "    ratio = imsize / max(image.shape)\n",
    "    image = cv2.resize(image, (0, 0), fx=ratio, fy=ratio)\n",
    "    return image\n",
    "\n",
    "def _pad_to_square(image: np.ndarray) -> np.ndarray:\n",
    "    height, width = image.shape[:2]\n",
    "    max_size = max(height, width)\n",
    "    image = np.pad(image, ((0, max_size - height), (0, max_size - width), (0, 0)))\n",
    "    return image\n",
    "\n",
    "def preprocess(images, imsize=416, mean=[0, 0, 0], std=[1, 1, 1], device='cpu'):\n",
    "    mean = torch.tensor(mean, dtype=torch.float, device=device).view(1, 3, 1, 1)\n",
    "    std = torch.tensor(std, dtype=torch.float, device=device).view(1, 3, 1, 1)\n",
    "\n",
    "    samples = [_resize(image, imsize=imsize) for image in images]\n",
    "    samples = [_pad_to_square(sample) for sample in samples]\n",
    "    samples = [cv2.cvtColor(sample, cv2.COLOR_BGR2RGB) for sample in samples]\n",
    "    samples = [torch.from_numpy(sample) for sample in samples]\n",
    "    samples = torch.stack(samples, dim=0).to(device)\n",
    "    samples = samples.permute(0, 3, 1, 2).contiguous()\n",
    "    samples = (samples.float().div(255.) - mean) / std\n",
    "\n",
    "    scales = [max(image.shape[:2]) / imsize for image in images]\n",
    "\n",
    "    return images, scales, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e819d4ff-17c1-43f1-bbe1-ab9ef0b1994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import ops\n",
    "from typing import Tuple, List\n",
    "\n",
    "\n",
    "def inference(\n",
    "        predictions: Tuple[torch.Tensor],\n",
    "        anchors: List[List[Tuple[float, float]]],\n",
    "        image_size: int = 416,\n",
    "        iou_threshold: float = 0.5,\n",
    "        score_threshold: float = 0.05\n",
    "    ):\n",
    "    '''get all boxes at gird S x S (grid_size = image_size / S)\n",
    "    Args:\n",
    "        preds: Tuple[[N x 3 x S x S x (tp, tx, ty, tw, th, n_classes)]] with S = [13, 26, 52]\n",
    "        anchors: [3 x 3 x 2] (pw, ph with size in [0, 1])  (relative to image_size)\n",
    "    Outputs:\n",
    "        scores: [N x (3 * (S1 * S1 + S2 * S2 + S3 * S3))]\n",
    "        labels: [N x (3 * (S1 * S1 + S2 * S2 + S3 * S3))]\n",
    "        bboxes: [N x (3 * (S1 * S1 + S2 * S2 + S3 * S3)) x 4], with [x1 y1 x2 y2].\n",
    "    '''\n",
    "    device = predictions[0].device\n",
    "    batch_size = predictions[0].shape[0]\n",
    "\n",
    "    batch_boxes, batch_labels, batch_scores = [], [], []\n",
    "\n",
    "    for i, pred in enumerate(predictions):\n",
    "        S = pred.shape[2]\n",
    "\n",
    "        # anchor: 1 x 3 x 1 x 1 x 2\n",
    "        anchor = torch.tensor(anchors[i], device=device, dtype=torch.float)  # anchor: 3 x 2\n",
    "        anchor = anchor.reshape(1, 3, 1, 1, 2)\n",
    "\n",
    "        # N x 3 x S x S\n",
    "        x_indices = torch.arange(S).repeat(batch_size, 3, S, 1).to(device)\n",
    "        y_indices = x_indices.permute(0, 1, 3, 2)\n",
    "        \n",
    "        # N x 3 x S x S -> reshape: N x (3 * S * S)\n",
    "        # score = sigmoid(tp)\n",
    "        scores = torch.sigmoid(pred[..., 0]).reshape(batch_size, -1)\n",
    "\n",
    "        # N x 3 x S x S -> reshape: N x (3 * S * S)\n",
    "        labels = torch.argmax(pred[..., 5:], dim=-1).reshape(batch_size, -1)\n",
    "\n",
    "        # xy: N x 3 x S x S x 2 (center of bboxes)\n",
    "        # bx = sigmoid(tx) + cx, by = sigmoid(ty) + cy\n",
    "        bx = (torch.sigmoid(pred[..., 1]) + x_indices) * (image_size / S)\n",
    "        by = (torch.sigmoid(pred[..., 2]) + y_indices) * (image_size / S)\n",
    "        bxy = torch.stack([bx, by], dim=-1)\n",
    "\n",
    "        # wh: N x 3 x S x S x 2 (width, height of bboxes)\n",
    "        # bw = pw * e ^ tw, bh = ph * e ^ th\n",
    "        bwh = (image_size * anchor) * torch.exp(pred[..., 3:5])\n",
    "\n",
    "        # boxes (x1 y1 x2 y2 type): N x (3 * S * S) x 4\n",
    "        boxes = torch.cat([bxy - bwh / 2, bxy + bwh / 2], dim=-1).reshape(batch_size, -1, 4)\n",
    "        boxes = torch.clamp(boxes, min=0, max=image_size)\n",
    "\n",
    "        batch_boxes.append(boxes)\n",
    "        batch_labels.append(labels)\n",
    "        batch_scores.append(scores)\n",
    "\n",
    "    batch_labels = torch.cat(batch_labels, dim=1)  # [N x (3 * (S1 * S1 + S2 * S2 + S3 * S3))]\n",
    "    batch_scores = torch.cat(batch_scores, dim=1)  # [N x (3 * (S1 * S1 + S2 * S2 + S3 * S3))]\n",
    "    batch_boxes = torch.cat(batch_boxes, dim=1)  # [N x (3 * (S1 * S1 + S2 * S2 + S3 * S3)) x 4]\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for batch_id in range(batch_size):\n",
    "        score_indices = batch_scores[batch_id, :] > score_threshold\n",
    "\n",
    "        if score_indices.sum() == 0:\n",
    "            predictions.append(\n",
    "                {\n",
    "                    'boxes': torch.tensor([[0, 0, 1, 1]], dtype=torch.float, device=device),\n",
    "                    'labels': torch.tensor([-1], dtype=torch.int64, device=device),\n",
    "                    'scores': torch.tensor([0], dtype=torch.float, device=device)\n",
    "                }\n",
    "            )\n",
    "\n",
    "            continue\n",
    "\n",
    "        boxes = batch_boxes[batch_id, score_indices, :]\n",
    "        labels = batch_labels[batch_id, score_indices]\n",
    "        scores = batch_scores[batch_id, score_indices]\n",
    "\n",
    "        nms_indices = ops.boxes.batched_nms(\n",
    "            boxes=boxes, scores=scores, idxs=labels,\n",
    "            iou_threshold=iou_threshold\n",
    "        )\n",
    "\n",
    "        if nms_indices.shape[0] != 0:\n",
    "            predictions.append(\n",
    "                {\n",
    "                    'boxes': boxes[nms_indices, :],\n",
    "                    'labels': labels[nms_indices],\n",
    "                    'scores': scores[nms_indices]\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            predictions.append(\n",
    "                {\n",
    "                    'boxes': torch.tensor([[0, 0, 1, 1]], dtype=torch.float, device=device),\n",
    "                    'labels': torch.tensor([-1], dtype=torch.int64, device=device),\n",
    "                    'scores': torch.tensor([0], dtype=torch.float, device=device)\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afdd8388-946f-433e-809f-6140d64bbb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained weight\n",
    "model = YOLOv3(num_classes=20)\n",
    "state_dict = torch.load(f='checkpoint/pretrained_weight/78.1map_0.2threshold_PASCAL.tar', map_location='cpu')\n",
    "model.load_state_dict(state_dict=state_dict['state_dict'])\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcd8ec13-9522-43ee-b564-43db239762d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "image_paths = [\n",
    "    '../efficient_det_pytorch/dataset/PASCALVOC2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages/000023.jpg',\n",
    "    '../efficient_det_pytorch/dataset/PASCALVOC2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages/000012.jpg',\n",
    "    '../efficient_det_pytorch/dataset/PASCALVOC2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages/000016.jpg',\n",
    "]\n",
    "\n",
    "images = [cv2.imread(image_path) for image_path in image_paths]\n",
    "\n",
    "images, scales, samples = preprocess(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a191a66-9ec9-461a-9aa7-f3f8963e6549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([3, 3, 416, 416])\n",
      "Output Shape at S=13: torch.Size([3, 3, 13, 13, 25])\n",
      "Output Shape at S=26: torch.Size([3, 3, 26, 26, 25])\n",
      "Output Shape at S=52: torch.Size([3, 3, 52, 52, 25])\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "with torch.no_grad():\n",
    "    preds = model(samples)\n",
    "\n",
    "print(f'Input Shape: {samples.shape}')    \n",
    "print(f'Output Shape at S={preds[0].shape[2]}: {preds[0].shape}')\n",
    "print(f'Output Shape at S={preds[1].shape[2]}: {preds[1].shape}')\n",
    "print(f'Output Shape at S={preds[2].shape[2]}: {preds[2].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98f66f1d-73f7-47d4-94e2-dc086f6d76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocessing\n",
    "anchors = [[(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],    # S = 13\n",
    "           [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],   # S = 26\n",
    "           [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],]  # S = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b05a451-896a-42a7-9349-842c6d2fc095",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = inference(\n",
    "    predictions=preds,\n",
    "    anchors=anchors,\n",
    "    image_size=416,\n",
    "    iou_threshold=0.5,\n",
    "    score_threshold=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b52bfbe-22dc-4cbe-be81-7ea9289c2280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[  9.4115,  11.4099, 237.5261, 397.4678],\n",
       "          [178.3522, 178.9196, 293.7810, 403.9183],\n",
       "          [  3.0243, 170.0002, 227.6837, 416.0000],\n",
       "          [177.9559,  20.7553, 292.5116, 388.3447],\n",
       "          [  0.0000,   6.5021, 101.8935, 352.0404],\n",
       "          [  0.0000, 190.1166,  91.4532, 402.8295],\n",
       "          [194.3734,  22.5865, 275.5323, 272.7602]]),\n",
       "  'labels': tensor([14,  1,  1, 14, 14,  1, 14]),\n",
       "  'scores': tensor([0.8944, 0.8688, 0.8530, 0.8383, 0.8261, 0.8107, 0.5676])},\n",
       " {'boxes': tensor([[126.4862,  70.2691, 286.6494, 227.7021]]),\n",
       "  'labels': tensor([6]),\n",
       "  'scores': tensor([0.8998])},\n",
       " {'boxes': tensor([[ 72.8772,  36.9785, 282.7292, 398.4085]]),\n",
       "  'labels': tensor([1]),\n",
       "  'scores': tensor([0.8798])}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df470f41-bb44-4306-b568-67ab2b7371d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes2idx = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4,\n",
    "               'bus': 5, 'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, 'diningtable': 10,\n",
    "               'dog': 11, 'horse': 12, 'motorbike': 13, 'person': 14, 'pottedplant': 15,\n",
    "               'sheep': 16, 'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
    "classes = list(classes2idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25cbf58d-770c-4b96-9714-b28e5aa2c1c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-19d7c97e95d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                  np.random.randint(0, 150))\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             cv2.rectangle(\n\u001b[1;32m     17\u001b[0m                 \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label' is not defined"
     ]
    }
   ],
   "source": [
    "for image, scale, pred in zip(images, scales, predictions):\n",
    "    thickness = max(image.shape) // 600\n",
    "    fontscale = max(image.shape) / 700\n",
    "    boxes = pred['boxes'].cpu().numpy()\n",
    "    labels = pred['labels'].cpu().numpy()\n",
    "    scores = pred['scores'].cpu().numpy()\n",
    "    class_names = [classes[label] for label in labels]\n",
    "    boxes[:, [0, 2]] = boxes[:, [0, 2]] * scale\n",
    "    boxes[:, [1, 3]] = boxes[:, [1, 3]] * scale\n",
    "    boxes = boxes.astype(np.int32)\n",
    "    for box, score, class_name in zip(boxes, scores, class_names):\n",
    "        color = (np.random.randint(200, 255),\n",
    "                 np.random.randint(50, 200),\n",
    "                 np.random.randint(0, 150))\n",
    "#         if label != -1:\n",
    "        cv2.rectangle(\n",
    "            img=image,\n",
    "            pt1=tuple(box[:2]),\n",
    "            pt2=tuple(box[2:]),    \n",
    "            color=color,\n",
    "            thickness=thickness\n",
    "        )\n",
    "\n",
    "        cv2.putText(\n",
    "            img=image,\n",
    "            text=f'{class_name}: {score: .4f}',\n",
    "            org=tuple(box[:2]),\n",
    "            fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
    "            fontScale=fontscale,\n",
    "            color=color,\n",
    "            thickness=thickness,\n",
    "            lineType=cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(class_name, image)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d53420-64dc-4679-b9aa-272f2f6cbdef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
