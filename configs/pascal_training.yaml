data:
  train:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.pascal_dataset
        class: PascalDataset
        PascalDataset:
          imsize: 416
          VOC2012:
            image_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2012/JPEGImages/'''
            label_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2012/Annotations/'''
            txt_path: '''../efficient_det_pytorch/dataset/PASCALVOC2012/ImageSets/Segmentation/train.txt'''
          VOC2007:
            image_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages/'''
            label_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/Annotations/'''
          image_extent: '''.jpg'''
          label_extent: '''.xml'''
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
          classes:
            aeroplane: 0
            bicycle: 1
            bird: 2
            boat: 3
            bottle: 4
            bus: 5
            car: 6
            cat: 7
            chair: 8
            cow: 9
            diningtable: 10
            dog: 11
            horse: 12
            motorbike: 13
            person: 14
            pottedplant: 15
            sheep: 16
            sofa: 17
            train: 18
            tvmonitor: 19
          transforms:
            - iaa.Fliplr(p=0.5)
          S: [13, 26, 52]  # image_size // 32, image_size // 16, image_size // 8
          anchors: [
            [[116.48, 91.52], [158.08, 199.68], [374.4, 324.48]],  # S = 13
            [[29.12, 62.4 ], [62.4, 45.76], [58.24, 120.64]],  # S = 26
            [[8.32, 12.48], [16.64, 29.12], [33.28, 24.96]],  # S = 52
          ]
      batch_size: 32
      shuffle: True
      pin_memory: True
      num_workers: 12
      drop_last: False
      collate_fn: 'lambda batch:tuple(zip(*batch))'
  
  train_eval:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.pascal_dataset
        class: PascalDataset
        PascalDataset:
          imsize: 416
          VOC2012:
            image_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2012/JPEGImages/'''
            label_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2012/Annotations/'''
            txt_path: '''../efficient_det_pytorch/dataset/PASCALVOC2012/ImageSets/Segmentation/train.txt'''
          VOC2007:
            image_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages/'''
            label_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/Annotations/'''
          image_extent: '''.jpg'''
          label_extent: '''.xml'''
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
          classes:
            aeroplane: 0
            bicycle: 1
            bird: 2
            boat: 3
            bottle: 4
            bus: 5
            car: 6
            cat: 7
            chair: 8
            cow: 9
            diningtable: 10
            dog: 11
            horse: 12
            motorbike: 13
            person: 14
            pottedplant: 15
            sheep: 16
            sofa: 17
            train: 18
            tvmonitor: 19
          S: [13, 26, 52]  # image_size // 32, image_size // 16, image_size // 8
          anchors: [
            [[116.48, 91.52], [158.08, 199.68], [374.4, 324.48]],  # S = 13
            [[29.12, 62.4 ], [62.4, 45.76], [58.24, 120.64]],  # S = 26
            [[8.32, 12.48], [16.64, 29.12], [33.28, 24.96]],  # S = 52
          ]
      batch_size: 32
      shuffle: False
      pin_memory: True
      num_workers: 12
      drop_last: False
      collate_fn: 'lambda batch:tuple(zip(*batch))'
  
  valid:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.pascal_dataset
        class: PascalDataset
        PascalDataset:
          imsize: 416
          VOC2012:
            image_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2012/JPEGImages/'''
            label_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2012/Annotations/'''
            txt_path: '''../efficient_det_pytorch/dataset/PASCALVOC2012/ImageSets/Segmentation/val.txt'''
          VOC2007:
            image_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2007/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages/'''
            label_dir: '''../efficient_det_pytorch/dataset/PASCALVOC2007/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/Annotations/'''
          image_extent: '''.jpg'''
          label_extent: '''.xml'''
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
          classes:
            aeroplane: 0
            bicycle: 1
            bird: 2
            boat: 3
            bottle: 4
            bus: 5
            car: 6
            cat: 7
            chair: 8
            cow: 9
            diningtable: 10
            dog: 11
            horse: 12
            motorbike: 13
            person: 14
            pottedplant: 15
            sheep: 16
            sofa: 17
            train: 18
            tvmonitor: 19
          S: [13, 26, 52]  # image_size // 32, image_size // 16, image_size // 8
          anchors: [
            [[116.48, 91.52], [158.08, 199.68], [374.4, 324.48]],  # S = 13
            [[29.12, 62.4 ], [62.4, 45.76], [58.24, 120.64]],  # S = 26
            [[8.32, 12.48], [16.64, 29.12], [33.28, 24.96]],  # S = 52
          ]
      batch_size: 32
      shuffle: False
      pin_memory: True
      num_workers: 12
      drop_last: False
      collate_fn: 'lambda batch:tuple(zip(*batch))'

loss:
  module: flame.core.loss.yolov3_loss
  class: YOLOv3Loss
  YOLOv3Loss:
    lambda_obj: 1
    lambda_noobj: 10
    lambda_bbox: 1
    lambda_class: 1
    input_size: 416
    anchors: [
      [[116.48, 91.52], [158.08, 199.68], [374.4, 324.48]],  # S = 13
      [[29.12, 62.4 ], [62.4, 45.76], [58.24, 120.64]],  # S = 26
      [[8.32, 12.48], [16.64, 29.12], [33.28, 24.96]],  # S = 52
    ]

model:
  module: flame.core.model.model
  class: Model
  Model:
    # weight_path: '''checkpoint/pretrained_weight/78.1map_0.2threshold_PASCAL.tar'''
    in_channels: 3
    num_classes: 20
    # iou_threshold: 0.2
    # score_threshold: 0.2
    # anchors: [
    #   [[116.48, 91.52], [158.08, 199.68], [374.4, 324.48]],  # S = 13
    #   [[29.12, 62.4 ], [62.4, 45.76], [58.24, 120.64]],  # S = 26
    #   [[8.32, 12.48], [16.64, 29.12], [33.28, 24.96]],  # S = 52
    # ]

# optim:
#   module: torch.optim
#   class: Adam
#   Adam:
#     params: config['model'].parameters()
#     lr: 0.00001
#     weight_decay: 0.0001
optim:
  module: torch.optim
  class: SGD
  SGD:
    params: config['model'].parameters()
    lr: 0.08
    momentum: 0.9
    nesterov: True

train_evaluator:
  module: flame.handlers.metric_evaluator
  class: MetricEvaluator
  MetricEvaluator:
    dataset: config['data']['train_eval']
    device: '''cuda'''

valid_evaluator:
  module: flame.handlers.metric_evaluator
  class: MetricEvaluator
  MetricEvaluator:
    dataset: config['data']['valid']
    device: '''cuda'''

metrics:
  module: flame.handlers.metrics.metrics
  class: Metrics
  Metrics:
    metrics:
      loss:
        module: flame.handlers.metrics.loss.loss
        class: Loss
        Loss:
          loss_fn:
            module: flame.handlers.metrics.loss.yolov3_loss
            class: YOLOv3Loss
            YOLOv3Loss:
              lambda_obj: 1
              lambda_noobj: 10
              lambda_bbox: 1
              lambda_class: 1
              input_size: 416
              anchors: [
                [[116.48, 91.52], [158.08, 199.68], [374.4, 324.48]],  # S = 13
                [[29.12, 62.4 ], [62.4, 45.76], [58.24, 120.64]],  # S = 26
                [[8.32, 12.48], [16.64, 29.12], [33.28, 24.96]],  # S = 52
              ]
          output_transform: 'lambda x: (x[0], x[1])'
    attach_to:
      train_evaluator: '''train'''
      valid_evaluator: '''valid'''

screenlogger:
  module: flame.handlers.screenlogger
  class: ScreenLogger
  ScreenLogger:
    eval_names:
      - '''train''' 
      - '''valid'''

history:
  module: flame.handlers.checkpoint
  class: History

checkpoint_loader:
  module: flame.handlers.checkpoint
  class: CheckpointLoader
  CheckpointLoader:
    checkpoint_path: '''checkpoint/PASCAL/2110011416/best_model_30_loss=-1.4638.pt'''
    mode: '''retrain'''

terminate_on_nan:
  module: flame.handlers.terminate_on_nan
  class: TerminateOnNan

lr_scheduler:
  module: flame.handlers.lr_scheduler
  class: ReduceLROnPlateau
  ReduceLROnPlateau:
    score_name: '''loss'''
    evaluator_name: '''valid_evaluator'''
    mode: '''min'''
    patience: 5
    verbose: True

early_stopping:
  module: flame.handlers.early_stopping
  class: EarlyStopping
  EarlyStopping:
    score_name: '''loss'''
    evaluator_name: '''valid_evaluator'''
    mode: '''min'''
    patience: 10

best_saver:
  module: flame.handlers.checkpoint
  class: BestSaver
  BestSaver:
    dirname: '''checkpoint/PASCAL/'''
    score_name: '''loss'''
    mode: '''min'''
    evaluator_name: '''valid_evaluator'''
    n_saved: 1

backup_saver:
  module: flame.handlers.checkpoint
  class: BackupSaver
  BackupSaver:
    modules:
      - '''model'''
      - '''optim'''
      - '''backup_saver'''
      - '''best_saver'''
      - '''history'''
      - '''lr_scheduler'''
      - '''early_stopping'''
    dirname: '''checkpoint/PASCAL/'''
    save_interval: 1
    n_saved: 1

engine:
  module: flame.core.engine.trainer
  class: Trainer
  Trainer:
    dataset: config['data']['train']
    device: '''cuda'''
    max_epochs: 10000

extralibs:
  torch: torch
  iaa: imgaug.augmenters
